# Voice Implementation Plan â€” Twilio + Agent Core

## Overview
Transform the booking bot from WhatsApp-only to support voice calls via **Twilio Voice** with real-time speech-to-text (STT) and text-to-speech (TTS). The agent core will remain channel-agnostic; only the voice adapter will differ.

---

## 1. Services & Infrastructure Required

### Primary Services

| Service | Purpose | Why | Alternative |
|---------|---------|-----|-------------|
| **Twilio Voice** | Incoming/outgoing calls | Industry standard, webhooks, Media Streams | AWS Chime, Vonage |
| **Twilio Media Streams** | Real-time audio/transport | Bidirectional streaming, built-in to Twilio | WebRTC, raw SIP |
| **OpenAI Whisper API** | Speech-to-Text (STT) | Accurate Spanish, real-time capable | Google Cloud Speech, Azure Cognitive |
| **OpenAI TTS** | Text-to-Speech | Low latency, natural voices | Google TTS, Azure Speech, ElevenLabs |
| **Redis** | Session / state (shared) | Already in use for WhatsApp | PostgreSQL, DynamoDB |
| **WebSocket Server** | Real-time bidirectional comm | Required for Media Streams | HTTP long-polling (slower) |

### Environment Variables Needed
```bash
# Twilio Voice
TWILIO_ACCOUNT_SID=AC...
TWILIO_AUTH_TOKEN=...
TWILIO_PHONE_NUMBER=+529876543210
TWILIO_TWIML_URL=https://your-domain.com/voice/twiml

# OpenAI (already have)
OPENAI_API_KEY=sk-...

# WebSocket / Media Streams
VOICE_WEBSOCKET_URL=wss://your-domain.com/voice/media-stream
VOICE_WEBHOOK_URL=https://your-domain.com/voice/webhook
```

---

## 2. Architecture & Data Flow

### Call Lifecycle

```
User calls +52 XXX XXX XXXX (Twilio number)
    â†“
Twilio webhook â†’ POST /voice/webhook
    â†“
CreateCall event â†’ agent_core.handleIncoming({ channel: 'voice', phone, meta })
    â†“
Session loaded from Redis
    â†“
Twilio Media Streams WebSocket established
    â†“
Audio frames â†’ Whisper STT â†’ transcripts
    â†“
Transcripts â†’ agent_core (same as WhatsApp)
    â†“
Agent decision (reply, get_hours, confirm, escalate)
    â†“
Response text â†’ OpenAI TTS â†’ audio chunks
    â†“
Audio â†’ Twilio Media Streams â†’ User's phone
    â†“
User speaks â†’ repeat STT â†’ interrupt (if needed) â†’ repeat
    â†“
Booking confirmed / Escalated / Hung up
    â†“
Session saved to Redis, call ended
```

### Key Difference from WhatsApp
- **WhatsApp**: Request/response cycles, discrete messages
- **Voice**: Continuous bidirectional streaming, interrupts mid-sentence, natural turn-taking

---

## 3. Implementation Phases

### Phase 1: Twilio Setup & Incoming Calls (Week 1)
**Goal**: Answer calls, detect speaker, load session

**Deliverables**:
1. Install `twilio` npm package
2. Create `/voice/webhook` endpoint (TwiML response)
3. Create `/voice/media-stream` WebSocket endpoint
4. Detect caller phone â†’ load/create session from Redis
5. Start Media Streams connection
6. Log call metadata

**Code Structure**:
```
index.js (new routes)
â”œâ”€â”€ POST /voice/webhook â†’ createCall
â”œâ”€â”€ POST /voice/twiml â†’ return TwiML with Media Streams URL
â””â”€â”€ WS /voice/media-stream â†’ handle audio + setup

adapters/voice.js (new)
â”œâ”€â”€ parseMediaStreamEvent(chunk)
â”œâ”€â”€ encodeAudioForWhisper(raw)
â”œâ”€â”€ decodeAudioFromTTS(buffer)
â””â”€â”€ sendAudioToUser(stream, buffer)
```

### Phase 2: Speech-to-Text (Week 2)
**Goal**: Convert user audio â†’ text â†’ agent_core

**Deliverables**:
1. Whisper API integration for STT
2. Handle partial transcripts (for real-time feedback)
3. Final transcript confidence scoring
4. Buffer audio frames, send periodically to Whisper
5. Extract transcript â†’ send to agentCore.handleIncoming

**Implementation**:
```javascript
// On each audio frame from Twilio:
audioBuffer.push(frame);

// Every 2 seconds or on silence:
if (bufferReady) {
  const transcript = await whisperSOT(audioBuffer);
  // Send to agent
  const action = await agentCore.handleIncoming({
    channel: 'voice',
    phone: caller,
    text: transcript.text,
    isFinal: transcript.isFinal
  });
}
```

### Phase 3: Text-to-Speech & Audio Output (Week 3)
**Goal**: Agent response â†’ audio â†’ user's phone

**Deliverables**:
1. OpenAI TTS integration
2. Convert agent text responses â†’ audio chunks
3. Send audio via Media Streams in real-time
4. Handle interrupts (user speaks while agent is talking)
5. Graceful fallback if TTS fails

**Implementation**:
```javascript
// When agent sends reply action:
const replyText = action.payload.message;

// Stream TTS audio
const audioStream = await tts.stream(replyText, {
  voice: 'nova',
  speed: 1.0
});

// Send chunks to user in real-time
for await (const chunk of audioStream) {
  mediaStream.send(chunk);
}
```

### Phase 4: Interrupts & Turn-Taking (Week 4)
**Goal**: Natural conversation, user can interrupt agent

**Deliverables**:
1. Detect user speaking while agent is still talking
2. Stop TTS immediately, analyze silence/speech
3. Interrupt agent gracefully (cut off reply, ask user to repeat)
4. Proper state machine: WAITING â†’ LISTENING â†’ TRANSCRIBING â†’ AGENT_DECISION â†’ SPEAKING
5. Test with real users

**State Machine**:
```
WAITING â†’ (user speaks) â†’ LISTENING
LISTENING â†’ (transcript ready) â†’ AGENT_DECIDING
AGENT_DECIDING â†’ SPEAKING (TTS)
SPEAKING â†’ (user interrupts) â†’ STOP_TTS, go to LISTENING
SPEAKING â†’ (complete) â†’ WAITING
```

---

## 4. Integration with Agent Core

The **agent_core.js** is already channel-agnostic. Min changes needed:

### Current Agent Core API
```javascript
handleIncoming(event) {
  // event: { channel, phone, text, raw, msgId, ts }
  // returns: { actions: [...], session }
}
```

### Voice-Specific Event Fields
```javascript
{
  channel: 'voice',
  phone: '+525574599078',
  text: 'Quiero reservar pÃ¡del para maÃ±ana',
  isFinal: true,
  isMidTurn: false,  // NEW: true if partial transcript
  callSid: 'CA....',  // NEW: Twilio call ID
  timestamp: Date.now()
}
```

### Voice-Specific Actions (additive, not breaking)
```javascript
{
  type: 'send_text',
  payload: { message: '...' }  // Agent sends text
}
// Voice adapter AUTOMATICALLY converts to TTS + audio

{
  type: 'interrupt',
  payload: { reason: 'user_spoke' }  // NEW: Tell agent to pause
}

{
  type: 'confirm_booking',
  payload: { ... }  // Same as WhatsApp
}

{
  type: 'escalate_to_human',
  payload: { reason: '...' }  // Hang up, call staff
}
```

**No changes needed to agent_core.js logic** â€” voice adapter handles audio transport.

---

## 5. Services Implementation Details

### 5.1 Twilio Voice Integration

**Install**:
```bash
npm install twilio twilio-media-streams
```

**Phone Number**: Buy or configure in Twilio Console
```
+52 ??? (Mexican number)
Webhook URL: https://your-domain.com/voice/twiml
```

**Call Flow**:
1. User dials â†’ Twilio hits `/voice/twiml`
2. Server returns TwiML with Media Streams URL
3. Twilio connects WebSocket to `/voice/media-stream`
4. Audio streams in real-time

**TwiML Response** (example):
```xml
<Response>
  <Say language="es-MX">Un momento, conectando...</Say>
  <Connect>
    <Stream url="wss://your-domain.com/voice/media-stream?CallSid={CallSid}&From={From}" />
  </Connect>
</Response>
```

### 5.2 Whisper STT

**How it works**:
- Buffer 2â€“3 sec of audio
- Send `.wav` to Whisper API
- Get transcript + confidence
- Cost: ~$0.02 per 15 min audio

**Integration**:
```javascript
const audioPath = '/tmp/audio.wav';
const response = await openai.audio.transcriptions.create({
  file: fs.createReadStream(audioPath),
  model: 'whisper-1',
  language: 'es'  // Spanish
});
const text = response.text;
```

### 5.3 OpenAI TTS

**How it works**:
- Send text (e.g., "Para Padel el 11, tengo: 10:00, 14:00...")
- Get MP3 audio stream
- Send to Twilio Media Streams
- Cost: ~$0.015 per 1K characters

**Integration**:
```javascript
const response = await openai.audio.speech.create({
  model: 'tts-1',  // Lower latency
  voice: 'nova',   // Spanish-friendly
  input: replyText
});
const audioBuffer = Buffer.from(await response.arrayBuffer());
```

### 5.4 Media Streams WebSocket

**What we receive** (audio from user):
```json
{
  "type": "media",
  "media": {
    "payload": "[base64 audio]"
  }
}
```

**What we send back** (audio to user):
```json
{
  "type": "media",
  "media": {
    "payload": "[base64 audio]"
  }
}
```

**Handling**:
```javascript
const wss = new WebSocketServer({ port: 8080 });
wss.on('connection', (ws) => {
  ws.on('message', (msg) => {
    const event = JSON.parse(msg);
    if (event.type === 'media') {
      const audioChunk = Buffer.from(event.media.payload, 'base64');
      // Process audio â†’ STT â†’ agent â†’ TTS â†’ send back
    }
  });
});
```

---

## 6. Conversation Flow Example

**User calls, bot greets**:
```
User dials +52...
Twilio connects Media Streams
Bot (TTS): "Hola, bienvenido a Black Padel. Â¿CÃ³mo puedo ayudarte?"
```

**User responds**:
```
User (speaks): "Quiero reservar pÃ¡del para maÃ±ana"
Whisper (STT): "Quiero reservar pÃ¡del para maÃ±ana"
Agent core: decision = { action: 'get_hours', message: 'Para Padel el 11...' }
Bot (TTS): "Para Padel el 11 de febrero, tengo: 10:00, 14:00... Â¿A quÃ© hora prefieres?"
```

**User picks time**:
```
User: "A las 14 horas"
Whisper: "A las 14 horas"
Agent core: decision = { action: 'confirm_reserva', ... }
Bot (TTS): "Perfecto. Entonces confirmamos: Padel el 11 a las 14:00. Â¿Te parece bien?"
```

**User confirms**:
```
User: "SÃ­, por favor"
Whisper: "SÃ­, por favor"
Agent core: invoke confirmBooking() â†’ success
Bot (TTS): "Â¡Listo! Te llegarÃ¡ confirmaciÃ³n al WhatsApp. Gracias."
Call ends
```

---

## 7. Error Handling & Fallbacks

| Scenario | Action |
|----------|--------|
| Whisper fails (timeout) | Replay: "No entendÃ­. Â¿Puedes repetir?" |
| User is silent > 10s | Prompt: "Â¿Sigues ahÃ­?" |
| TTS takes > 3s | Start playing while generating (stream) |
| Agent escalates | Play: "Te conecto con un agente. Espera un momento." â†’ Call transfer or hang up |
| Network drops | Fallback: Send SMS confirmation |
| User hangs up | Log call end, mark session incomplete |

---

## 8. Testing & Validation

### Unit Tests
```javascript
// Test Whisper parsing
test('transcribeAudio', async () => {
  const audio = fs.readFileSync('test.wav');
  const text = await transcribeAudio(audio);
  expect(text).toContain('pÃ¡del');
});

// Test TTS generation
test('generateSpeech', async () => {
  const audio = await generateSpeech('Hola');
  expect(audio).toBeInstanceOf(Buffer);
  expect(audio.length).toBeGreaterThan(100);
});
```

### Integration Tests
```javascript
// Simulate Media Streams event
test('handleMediaStream', async () => {
  const audioChunk = Buffer.from('...');  // Real audio
  const response = await handleMediaStreamChunk(audioChunk, session);
  expect(response.type).toBe('media');
});
```

### E2E Testing (Manual)
1. Call the Twilio number from real phone
2. Speak a few requests: "PÃ¡del maÃ±ana", "10 de la maÃ±ana", "Confirma"
3. Verify booking appears in Bubble
4. Check logs for Whisper/TTS/agent decisions

---

## 9. Cost Estimate (Monthly)

| Service | Per-Unit | Estimated Usage | Monthly Cost |
|---------|----------|-----------------|--------------|
| Twilio (incoming calls) | $0.0085/min | 1000 min | ~$8.50 |
| Whisper (STT) | $0.02 / 15 min | 1000 min = 67 calls | ~$2.67 |
| OpenAI TTS | $0.015 / 1K chars | ~50K chars (calls) | ~$0.75 |
| Twilio Media Streams | Included | â€” | $0 |
| OpenAI GPT-4o-mini | $0.15/$0.60 / 1M tokens | ~10K prompts | ~$2 |
| **Total** | â€” | â€” | **~$14â€“15/month** |

(Low usage; scales well if > 10K calls/month)

---

## 10. Roadmap & Milestones

| Week | Phase | Deliverables |
|------|-------|--------------|
| Week 1â€“2 | Setup & STT | Twilio connection, Whisper integration, session persistence |
| Week 3 | TTS | OpenAI TTS, real-time audio streaming |
| Week 4â€“5 | Testing & Polish | Interrupts, error handling, edge cases |
| Week 6 | Go-live | Soft launch, monitoring, stress test |

---

## 11. Risk Mitigations

| Risk | Solution |
|------|----------|
| STT latency (Whisper) | Buffer intelligently; show partial transcripts |
| Echo/duplex audio issues | Use Twilio's built-in echo cancellation |
| TTS quality (non-native speaker) | Test with real users; use `tts-1-hd` if needed |
| Call dropping | Implement session recovery; log call ID |
| Concurrent calls spike | Use queue; Twilio auto-scales |

---

## 12. Summary

**What changes**:
- Add Twilio integration (new routes, WebSocket)
- Add Whisper + TTS (audio codec/streaming)
- Add voice adapter (thin layer)

**What doesn't change**:
- Agent core logic (same for all channels)
- Session model (phone + metadata)
- Booking/confirmation flow

**Timeline**: ~4â€“6 weeks for production-ready voice
**Budget**: $15â€“20/month for low-to-medium volume
**Team**: 1 engineer (part-time) + QA for testing

---

## Next Steps
1. âœ… **Review this plan** with team
2. â¬œ Set up Twilio account + buy Mexican phone number
3. â¬œ Implement Phase 1 (Twilio webhook + Media Streams)
4. â¬œ Implement Phase 2 (Whisper STT)
5. â¬œ Implement Phase 3 (OpenAI TTS)
6. â¬œ Test with real calls
7. â¬œ Monitor & iterate

Ready to start Phase 1? ðŸŽ¤
